{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 在CTR点击率预估中，使用GBDT+LR的原理是什么？\n",
    "答：GBDT做好预测的时候，得到的是很多决策树和最终的叶节点，但没有输出二分类概率，所以将GBDT的输出作为LR的输入，输出二分类的概率\n",
    "\n",
    "## 2. Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization）\n",
    "答：wide是指将原始的数据讲过onehot编码等方式形成非组合特征，deep是指将原始特征输入到网络层进行embedding得到隐性特征，将wide 和deep两部分都输入到接下来的隐藏层再进行神经网络训练。因为输入是原始特征加embedding后的隐性特征，所以说具备了记忆能力和泛化能力。\n",
    "\n",
    "## 3. 在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？\n",
    "答：FM对特征embedding初始化，再加入DNN进行训练，代表模型有FNN模型。又或者有deepFM模型，使用FM对原始特征进行embedding，再跟经过隐藏层的特征一起输入到DNN结构中，并行结构。还有NFM，将Fm的结构输入到DNN中\n",
    "\n",
    "## 4. Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？\n",
    "答：基于统计的预测值偏差，计算出用户对整体商品的偏差和计算出商品对整体的偏差来纠正用户的打分。KNN使用pearson corelation替代偏差的均值\n",
    "\n",
    "## 5. GBDT和随机森林都是基于树的算法，它们有什么区别？\n",
    "答：\n",
    "\n",
    "## 6. 基于邻域的协同过滤都有哪些算法，请简述原理\n",
    "答：基于用户的协同过滤：1.根据相似度计算出相似度最高的k个用户  2.用户u对物品i的相似度，等价于K个邻居对物品i的兴趣度\n",
    "基于物品 item 的协同过滤：1.计算物品之间的相似度  2.根据用户对物品i的兴趣度，寻找与物品最近邻的k个物品进行推荐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
