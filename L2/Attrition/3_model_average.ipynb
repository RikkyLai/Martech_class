{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "def stacking(model, train_data, train_target, test_data, n_fold):\n",
    "    \"\"\"\n",
    "    :param model:  模型算法\n",
    "    :param train_data:  训练集(不含带预测的目标特征)\n",
    "    :param train_target:  需要预测的目标特征\n",
    "    :param test_data:   测试集\n",
    "    :param n_fold:   交叉验证的折数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_fold, random_state=1)  # StratifiedKFold 默认分层采样\n",
    "    train_pred = np.zeros((train_data.shape[0], 1), int)   # 存储训练集预测结果\n",
    "    test_pred = np.zeros((test_data.shape[0], 1), int)  # 存储测试集预测结果 行数：len(test_data) ,列数：1列\n",
    "    for skf_index, (train_index, val_index) in enumerate(skf.split(train_data, train_target)):\n",
    "        print('第 ', skf_index+1, ' 折交叉验证开始... ')\n",
    "        # 训练集划分\n",
    "        x_train, x_val = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "        y_train, y_val = train_target.iloc[train_index], train_target.iloc[val_index]\n",
    "        # 模型构建\n",
    "        y_train = np.ravel(y_train)   # 向量转成数组\n",
    "        model.fit(X=x_train, y=y_train)\n",
    "        # 模型预测\n",
    "        accs = accuracy_score(y_val, model.predict(x_val))\n",
    "        print('第 ', skf_index+1, ' 折交叉验证 :  accuracy ： ', accs)\n",
    " \n",
    "        # 训练集预测结果\n",
    "        val_pred = model.predict_proba(x_val)[:, 1]\n",
    "        for i in range(len(val_index)):\n",
    "            train_pred[val_index[i]] = val_pred[i]\n",
    "        # 保存测试集预测结果\n",
    "        test_pred = np.column_stack((test_pred, model.predict_proba(test_data)[:, 1]))  # 将矩阵按列合并\n",
    " \n",
    "    test_pred_mean = np.mean(test_pred, axis=1)  # 按行计算均值(会出现小数)\n",
    "    test_pred_mean = pd.DataFrame(test_pred_mean)   # 转成DataFrame\n",
    "#     test_pred_mean = test_pred_mean.apply(lambda x: round(x))  # 小数需要四舍五入成整数\n",
    "    return np.ravel(test_pred_mean), train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================logistic regression==============================\n",
      "第  1  折交叉验证开始... \n",
      "第  1  折交叉验证 :  accuracy ：  0.8389830508474576\n",
      "第  2  折交叉验证开始... \n",
      "第  2  折交叉验证 :  accuracy ：  0.8595744680851064\n",
      "第  3  折交叉验证开始... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第  3  折交叉验证 :  accuracy ：  0.8638297872340426\n",
      "第  4  折交叉验证开始... \n",
      "第  4  折交叉验证 :  accuracy ：  0.8425531914893617\n",
      "第  5  折交叉验证开始... \n",
      "第  5  折交叉验证 :  accuracy ：  0.8680851063829788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "\n",
    "train_lr = train.copy(deep=True)\n",
    "test_lr = test.copy(deep=True)\n",
    "\n",
    "train_lr['Attrition'] = train_lr['Attrition'].map(lambda x: 1 if x=='Yes' else 0)\n",
    "test_lr['Attrition'] = -1\n",
    "test_lr = test_lr[train_lr.columns]\n",
    "data = pd.concat([train_lr, test_lr])\n",
    "\n",
    "data = data.drop(['EmployeeNumber', 'EmployeeCount', 'StandardHours'], axis=1)\n",
    "\n",
    "for attr in cols:\n",
    "    new_attr = pd.DataFrame()\n",
    "    new_attr = pd.get_dummies(data[attr],prefix=attr)\n",
    "    data = pd.concat([data, new_attr], axis=1)\n",
    "    data = data.drop([attr], axis=1)\n",
    "train_lr = data[data['Attrition'] != -1]\n",
    "test_lr = data[data['Attrition'] == -1]\n",
    "test_lr = test_lr.drop('Attrition', axis=1)\n",
    "\n",
    "# 归一化数值比较大的向量\n",
    "Min_max_cols=['TotalWorkingYears', 'Age', 'MonthlyIncome', 'DailyRate', 'DistanceFromHome', 'HourlyRate']\n",
    "for col in Min_max_cols:\n",
    "    min_max = MinMaxScaler()\n",
    "    train_lr[col] = min_max.fit_transform(train_lr[col].values.reshape(-1, 1))\n",
    "    test_lr[col] = min_max.transform(test_lr[col].values.reshape(-1, 1))\n",
    "\n",
    "# 采用LR模型\n",
    "model_lr = LogisticRegression(max_iter=100, verbose=True, random_state=33, tol=1e-4)\n",
    "print('==============================logistic regression==============================')\n",
    "lr_test_pred, lr_train_pred = stacking(model=model_lr, train_data=train_lr.drop(['user_id', 'Attrition'], axis=1), train_target=train_lr['Attrition'], test_data=test_lr.drop('user_id', axis=1), n_fold=5)\n",
    "\n",
    "\n",
    "# model_lr.fit(train_lr.drop(['user_id', 'Attrition'], axis=1), train_lr['Attrition'])\n",
    "\n",
    "# predict_lr = model_lr.predict_proba(test_lr.drop('user_id', axis=1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
      "       'DistanceFromHome', 'Education', 'EducationField',\n",
      "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
      "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
      "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18',\n",
      "       'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
      "       'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears',\n",
      "       'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',\n",
      "       'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
      "       'YearsWithCurrManager'],\n",
      "      dtype='object')\n",
      "[1, 3, 6, 8, 12, 14, 18, 19]\n",
      "==============================catboost==============================\n",
      "0:\ttest: 0.5807292\tbest: 0.5807292 (0)\ttotal: 111ms\tremaining: 1m 51s\n",
      "50:\ttest: 0.8094363\tbest: 0.8094363 (50)\ttotal: 1.06s\tremaining: 19.8s\n",
      "100:\ttest: 0.8187806\tbest: 0.8187806 (100)\ttotal: 2.14s\tremaining: 19.1s\n",
      "150:\ttest: 0.8123468\tbest: 0.8187806 (100)\ttotal: 3.05s\tremaining: 17.1s\n",
      "200:\ttest: 0.8121936\tbest: 0.8187806 (100)\ttotal: 3.86s\tremaining: 15.4s\n",
      "250:\ttest: 0.8117341\tbest: 0.8187806 (100)\ttotal: 4.58s\tremaining: 13.7s\n",
      "300:\ttest: 0.8129596\tbest: 0.8187806 (100)\ttotal: 5.26s\tremaining: 12.2s\n",
      "350:\ttest: 0.8158701\tbest: 0.8187806 (100)\ttotal: 5.92s\tremaining: 10.9s\n",
      "400:\ttest: 0.8140319\tbest: 0.8187806 (100)\ttotal: 6.59s\tremaining: 9.85s\n",
      "450:\ttest: 0.8157169\tbest: 0.8187806 (100)\ttotal: 7.54s\tremaining: 9.17s\n",
      "500:\ttest: 0.8143382\tbest: 0.8187806 (100)\ttotal: 8.3s\tremaining: 8.27s\n",
      "550:\ttest: 0.8152574\tbest: 0.8187806 (100)\ttotal: 8.99s\tremaining: 7.32s\n",
      "600:\ttest: 0.8151042\tbest: 0.8187806 (100)\ttotal: 9.64s\tremaining: 6.4s\n",
      "650:\ttest: 0.8167892\tbest: 0.8187806 (100)\ttotal: 10.3s\tremaining: 5.52s\n",
      "700:\ttest: 0.8175551\tbest: 0.8187806 (100)\ttotal: 10.9s\tremaining: 4.66s\n",
      "750:\ttest: 0.8175551\tbest: 0.8187806 (100)\ttotal: 11.6s\tremaining: 3.84s\n",
      "800:\ttest: 0.8196998\tbest: 0.8196998 (800)\ttotal: 12.3s\tremaining: 3.04s\n",
      "850:\ttest: 0.8216912\tbest: 0.8216912 (850)\ttotal: 13s\tremaining: 2.27s\n",
      "900:\ttest: 0.8209252\tbest: 0.8216912 (850)\ttotal: 13.7s\tremaining: 1.5s\n",
      "950:\ttest: 0.8236826\tbest: 0.8236826 (950)\ttotal: 14.3s\tremaining: 738ms\n",
      "999:\ttest: 0.8249081\tbest: 0.8249081 (999)\ttotal: 15s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8249080882\n",
      "bestIteration = 999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import catboost as cb\n",
    "# catboost的分类\n",
    "train_cb = train.copy(deep=True)\n",
    "test_cb = test.copy(deep=True)\n",
    "\n",
    "train_cb = train_cb.drop(['user_id', 'EmployeeCount', 'EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test_cb = test_cb.drop(['EmployeeCount', 'EmployeeNumber', 'StandardHours'], axis=1)\n",
    "train_cb['Attrition'] = train_cb['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_cb.drop('Attrition', axis=1), train_cb['Attrition'], test_size=0.2, random_state=40)\n",
    "print(train_cb.columns)\n",
    "model_cb = cb.CatBoostClassifier(iterations=1000,\n",
    "                                         depth=7,\n",
    "                                         learning_rate=0.01,\n",
    "                                         loss_function='Logloss',\n",
    "                                         eval_metric='AUC',\n",
    "                                         logging_level='Verbose',\n",
    "                                         metric_period=50)\n",
    "\n",
    "\n",
    "\n",
    "# 得到分类特征的列号\n",
    "categorical_features_indices = []\n",
    "for i in range(len(x_train.columns)):\n",
    "    if x_train.columns.values[i] in cols:\n",
    "        categorical_features_indices.append(i)\n",
    "print(categorical_features_indices)\n",
    "\n",
    "print('==============================catboost==============================')\n",
    "# cb_test_pred, cb_train_pred = stacking(model=model_cb, train_data=x_train, train_target=y_train, test_data=test_cb.drop('user_id', axis=1), n_fold=5)\n",
    "\n",
    "model_cb.fit(x_train, y_train, eval_set=(x_valid, y_valid), cat_features=categorical_features_indices)\n",
    "\n",
    "predict_cb = model_cb.predict_proba(test_cb.drop('user_id', axis=1))[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================随机森林模型==============================\n",
      "第  1  折交叉验证开始... \n",
      "第  1  折交叉验证 :  accuracy ：  0.8771186440677966\n",
      "第  2  折交叉验证开始... \n",
      "第  2  折交叉验证 :  accuracy ：  0.8680851063829788\n",
      "第  3  折交叉验证开始... \n",
      "第  3  折交叉验证 :  accuracy ：  0.8468085106382979\n",
      "第  4  折交叉验证开始... \n",
      "第  4  折交叉验证 :  accuracy ：  0.8638297872340426\n",
      "第  5  折交叉验证开始... \n",
      "第  5  折交叉验证 :  accuracy ：  0.8425531914893617\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingRegressor\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "train_gb = train.copy(deep=True)\n",
    "test_gb = test.copy(deep=True)\n",
    "\n",
    "test_gb['Attrition'] = -1\n",
    "test_gb = test_gb[train_gb.columns]\n",
    "data = pd.concat([train_gb, test_gb])\n",
    "\n",
    "data = data.drop(['EmployeeNumber', 'EmployeeCount', 'StandardHours'], axis=1)\n",
    "\n",
    "train_gb = data[data['Attrition'] != -1]\n",
    "test_gb = data[data['Attrition'] == -1]\n",
    "test_gb = test_gb.drop('Attrition', axis=1)\n",
    "train_gb['Attrition'] = train_gb['Attrition'].map(lambda x: 1 if x=='Yes' else 0) \n",
    "train_gb = train_gb.drop('user_id', axis=1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbe_list = []\n",
    "for col in cols:\n",
    "    lbe = LabelEncoder()\n",
    "    train_gb[col] = lbe.fit_transform(train_gb[col])\n",
    "    test_gb[col] = lbe.transform(test_gb[col])\n",
    "    lbe_list.append(lbe)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 三个初级学习器进行初级训练\n",
    "# 随机森林算法进行训练\n",
    "rf = RandomForestClassifier(n_jobs=-1, max_depth=100, n_estimators=800)\n",
    "print('==============================随机森林模型==============================')\n",
    "rf_test_pred, rf_train_pred = stacking(model=rf, train_data=train_gb.drop('Attrition', axis=1), train_target=train_gb['Attrition'], test_data=test_gb.drop('user_id', axis=1), n_fold=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = ( 0.4*lr_test_pred + 0.4*predict_cb + 0.2*rf_test_pred)\n",
    "\n",
    "submission = pd.DataFrame({'user_id': test['user_id'], 'Attrition': predict})\n",
    "submission.to_csv(\"submission_test2.csv\", index=False, sep=',', columns=['user_id', 'Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    988\n",
       "1    188\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gb['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Age', 'Attrition', 'BusinessTravel', 'DailyRate',\n",
       "       'Department', 'DistanceFromHome', 'Education', 'EducationField',\n",
       "       'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender',\n",
       "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
       "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
       "       'NumCompaniesWorked', 'Over18', 'OverTime', 'PercentSalaryHike',\n",
       "       'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours',\n",
       "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
       "       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
       "       'YearsSinceLastPromotion', 'YearsWithCurrManager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Age', 'BusinessTravel', 'DailyRate', 'Department',\n",
       "       'DistanceFromHome', 'Education', 'EducationField',\n",
       "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
       "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
       "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18',\n",
       "       'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
       "       'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears',\n",
       "       'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',\n",
       "       'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
       "       'Attrition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
